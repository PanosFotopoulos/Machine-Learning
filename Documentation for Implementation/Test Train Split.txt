To begin our machine learning project, we'll start by importing some crucial libraries:

 -import pandas as pd
 -import numpy as np
 -import seaborn as sns
 -import matplotlib as plt
 
Next, we'll define our DataFrame from the data:
df = pd.read_csv('mycsv')
For a successful machine learning project, it's essential to split our data into training and testing sets. 
This allows us to train our model on one portion of the data and evaluate its performance on another. 
Thankfully, the sklearn library provides a handy tool for this:

--- Splitting the Data into Training and Testing Sets---
From sklearn.model_selection import train_test_split.   X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.3,random_state=101)
Now, check if u need to drop a column (most likely will be the column you want to predict)
As we see there are two variables X,y with X_train, X_test, y_train, y_test, so now lets define this variable
X = df.drop('prediction_column',axis = 1)
y = df['prediction_column']

Keep in mind i train my model on X_train to predict y_train, and then from X_test predict y_test

Standardization --- import scaler (optimal) and scale ur data---
Standardization helps to ensure that each feature contributes equally to the model.
from sklearn.preprocessing import StandarScaler 
Mean = 0: The average value of each feature will be zero
Variance = 1: The standard deviation of each feature will be one, meaning the data will be spread out in a standard normal distribution.

Mean Calculation(.mean()):

Mean =  (-1.34164079 + ( -  0.4472136 ) + 0.4472136 + 1.34164079) / 4 = 0, The mean is 0, as expected.

Standard Deviation Calculation(.std()):

Variance = (-1.34164079-0)^2 + (-0.4472136-0)^2 + (0.4472136-0)^2 + (1.34164079-0)^2 / 4 = 1, Taking the square root of the variance gives us the standard deviation, which is 1.

Now that is very clear what mean and std is and how scaler works lets scale our data.

First step. Allow the scaler to learn how to scale the data properly with .fit

scaler.fit(X_train) In this step computes the mean and the standard deviation of each feature in X_train, Only fit on training data to prevend data leakage (SOS)
 
Second step. Transfrom our data

X_train = scaler.transfrom(X_train)
X_test = scaler.transform(X_test) 

--- Import Model ---
Now all the datas are ready to go. We need to import a model to fit. This can be what ever model actually help us to achive our goal, lets see how we code it.

from sklearn.linear_model import Your desire model
from sklearn.linear_model import Ridge
from sklearn.linear_model import LinearRegression

For the most of the models now the way of the implementation is pretty straight forward

Ridge_model = Ridge(alpha=1) 
LinearRegression_model = LinearRegression()

Train the data to the model

Ridge_model.fit(X_train,y_train)
LinearRegression_model.fit(X_train,y_train).

On this stage lets remind our steps. We starting with splitting the data to 70% train 30% testing , we transform the train data with the scaler, we imported our model
and we just trained. Let's predict now our 30% y_pred

Ridge_y_prediction = model.predict(X_train)
LinearRegression_y_prediction= model.predict(X_train)

--- Model evaluation ---
Last step lets evaluate our model 

from sklearn.metrics import mean_squared_error

mean_squared_error(y_test,y_pred)

To recap, we started by splitting our data into 70% training and 30% testing sets.
We then standardized the training data using a scaler, imported our desired models, and trained them. 
Finally, we predicted the target variable on the test set and evaluated the model using MSE.